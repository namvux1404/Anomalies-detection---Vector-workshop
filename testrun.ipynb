{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namvux1404/Anomalies-detection---Vector-workshop/blob/main/testrun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFAn6AKSjfKd",
        "outputId": "95b88626-d761-4860-f787-541991e3ccb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GDN'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 54 (delta 10), reused 6 (delta 6), pack-reused 27\u001b[K\n",
            "Receiving objects: 100% (54/54), 473.31 KiB | 21.51 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/d-ailin/GDN.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('./GDN/')"
      ],
      "metadata": {
        "id": "TyJhq3rqnWuG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EPtQuZSnmzN",
        "outputId": "8090f9a9-1374-43a6-99cd-b89813ebb95d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pjevXDirQLE",
        "outputId": "52b7f478-8e77-4017-bebf-7643a78cdc1c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/661.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/661.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=00e8b8b8b22a09b522012c9cf7bc38bd5a3a41873c254e396604a498e1d79218\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.1+cu118.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qt3w98ZXVw9",
        "outputId": "47581c4f-58c4-4c29-dfb9-c5c55b1d1d1a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
            "Collecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.1%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.17%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.1%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (884 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m884.9/884.9 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, torch_sparse, torch_cluster\n",
            "Successfully installed torch_cluster-1.6.1+pt20cu118 torch_scatter-2.1.1+pt20cu118 torch_sparse-0.6.17+pt20cu118 torch_spline_conv-1.2.2+pt20cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-iDRRqB4hUI",
        "outputId": "9b8e1200-2757-4c8e-90db-3e1443a1c3b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug 22 20:09:46 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run.sh 0 msl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUep2s20vr9e",
        "outputId": "8c5b43ba-d4a2-4114-a151-95462c8b2cad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GDN/models/GDN.py:161: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3571.)\n",
            "  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)\n",
            "epoch (0 / 30) (Loss:0.46357875, ACU_loss:18.07957128)\n",
            "epoch (1 / 30) (Loss:0.27831617, ACU_loss:10.85433066)\n",
            "epoch (2 / 30) (Loss:0.23245515, ACU_loss:9.06575081)\n",
            "epoch (3 / 30) (Loss:0.21231870, ACU_loss:8.28042926)\n",
            "epoch (4 / 30) (Loss:0.19132835, ACU_loss:7.46180575)\n",
            "epoch (5 / 30) (Loss:0.17451125, ACU_loss:6.80593877)\n",
            "epoch (6 / 30) (Loss:0.17282238, ACU_loss:6.74007301)\n",
            "epoch (7 / 30) (Loss:0.16401211, ACU_loss:6.39647238)\n",
            "epoch (8 / 30) (Loss:0.15154169, ACU_loss:5.91012604)\n",
            "epoch (9 / 30) (Loss:0.14382453, ACU_loss:5.60915673)\n",
            "epoch (10 / 30) (Loss:0.15088213, ACU_loss:5.88440290)\n",
            "epoch (11 / 30) (Loss:0.14205924, ACU_loss:5.54031017)\n",
            "epoch (12 / 30) (Loss:0.13832089, ACU_loss:5.39451490)\n",
            "epoch (13 / 30) (Loss:0.13223468, ACU_loss:5.15715254)\n",
            "epoch (14 / 30) (Loss:0.12521319, ACU_loss:4.88331434)\n",
            "epoch (15 / 30) (Loss:0.13063146, ACU_loss:5.09462697)\n",
            "epoch (16 / 30) (Loss:0.11924004, ACU_loss:4.65036149)\n",
            "epoch (17 / 30) (Loss:0.11678912, ACU_loss:4.55477560)\n",
            "epoch (18 / 30) (Loss:0.11746545, ACU_loss:4.58115266)\n",
            "epoch (19 / 30) (Loss:0.11410467, ACU_loss:4.45008232)\n",
            "epoch (20 / 30) (Loss:0.11625520, ACU_loss:4.53395277)\n",
            "epoch (21 / 30) (Loss:0.11443925, ACU_loss:4.46313070)\n",
            "epoch (22 / 30) (Loss:0.11031584, ACU_loss:4.30231784)\n",
            "epoch (23 / 30) (Loss:0.10802670, ACU_loss:4.21304117)\n",
            "epoch (24 / 30) (Loss:0.10871221, ACU_loss:4.23977602)\n",
            "epoch (25 / 30) (Loss:0.10824485, ACU_loss:4.22154911)\n",
            "epoch (26 / 30) (Loss:0.10685453, ACU_loss:4.16732654)\n",
            "epoch (27 / 30) (Loss:0.10491384, ACU_loss:4.09163974)\n",
            "epoch (28 / 30) (Loss:0.10526927, ACU_loss:4.10550160)\n",
            "epoch (29 / 30) (Loss:0.10410392, ACU_loss:4.06005295)\n",
            "=========================** Result **============================\n",
            "\n",
            "F1 score: 0.8817144447536878\n",
            "precision: 0.7946787148594378\n",
            "recall: 0.989375\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run.sh 0 msl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz6IVcHb3h7T",
        "outputId": "bc68864d-06b2-4baf-af15-3b59ef861784"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GDN/models/GDN.py:161: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3571.)\n",
            "  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)\n",
            "epoch (0 / 30) (Loss:0.40126185, ACU_loss:15.64921206)\n",
            "epoch (1 / 30) (Loss:0.23020027, ACU_loss:8.97781043)\n",
            "epoch (2 / 30) (Loss:0.21891579, ACU_loss:8.53771593)\n",
            "epoch (3 / 30) (Loss:0.20108926, ACU_loss:7.84248129)\n",
            "epoch (4 / 30) (Loss:0.18417725, ACU_loss:7.18291289)\n",
            "epoch (5 / 30) (Loss:0.16131762, ACU_loss:6.29138714)\n",
            "epoch (6 / 30) (Loss:0.14989740, ACU_loss:5.84599854)\n",
            "epoch (7 / 30) (Loss:0.14507586, ACU_loss:5.65795851)\n",
            "epoch (8 / 30) (Loss:0.14226651, ACU_loss:5.54839396)\n",
            "epoch (9 / 30) (Loss:0.13301261, ACU_loss:5.18749189)\n",
            "epoch (10 / 30) (Loss:0.13283342, ACU_loss:5.18050336)\n",
            "epoch (11 / 30) (Loss:0.13313371, ACU_loss:5.19221486)\n",
            "epoch (12 / 30) (Loss:0.12888184, ACU_loss:5.02639189)\n",
            "epoch (13 / 30) (Loss:0.12381278, ACU_loss:4.82869859)\n",
            "epoch (14 / 30) (Loss:0.12132498, ACU_loss:4.73167426)\n",
            "epoch (15 / 30) (Loss:0.11353833, ACU_loss:4.42799480)\n",
            "epoch (16 / 30) (Loss:0.10947291, ACU_loss:4.26944342)\n",
            "epoch (17 / 30) (Loss:0.11339633, ACU_loss:4.42245706)\n",
            "epoch (18 / 30) (Loss:0.10698349, ACU_loss:4.17235605)\n",
            "epoch (19 / 30) (Loss:0.10671622, ACU_loss:4.16193246)\n",
            "epoch (20 / 30) (Loss:0.10901902, ACU_loss:4.25174160)\n",
            "epoch (21 / 30) (Loss:0.10968370, ACU_loss:4.27766433)\n",
            "epoch (22 / 30) (Loss:0.11219957, ACU_loss:4.37578320)\n",
            "epoch (23 / 30) (Loss:0.10680082, ACU_loss:4.16523209)\n",
            "epoch (24 / 30) (Loss:0.10531332, ACU_loss:4.10721951)\n",
            "epoch (25 / 30) (Loss:0.10877027, ACU_loss:4.24204062)\n",
            "epoch (26 / 30) (Loss:0.10426462, ACU_loss:4.06632017)\n",
            "epoch (27 / 30) (Loss:0.10121143, ACU_loss:3.94724559)\n",
            "epoch (28 / 30) (Loss:0.10087058, ACU_loss:3.93395276)\n",
            "epoch (29 / 30) (Loss:0.10175392, ACU_loss:3.96840286)\n",
            "=========================** Result **============================\n",
            "\n",
            "F1 score: 0.8879023307436182\n",
            "precision: 0.7988017973040439\n",
            "recall: 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSUdwCAj8zMy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}